{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "from IPython.display import display, HTML\n",
    "from string import Template\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 指定字体路径\n",
    "font_path = '/storage/U-ViT/tools/Visualization/language/fonts/SimHei/SimHei.ttf'\n",
    "font_prop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "# 配置全局字体\n",
    "matplotlib.rcParams['font.family'] = font_prop.get_name()\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 导入display_attention函数\n",
    "\n",
    "from attention_visualizer import display_attention\n",
    "\n",
    "# # 创建测试数据\n",
    "# # 示例句子和相应的注意力权重\n",
    "# sentence = [\"这是\", \"一个\", \"注意力\", \"可视化\", \"测试\"]\n",
    "# attention_weights = [0.2, 0.5, 0.9, 0.7, 0.3]\n",
    "\n",
    "# 显示可视化结果\n",
    "# display_attention(sentence, attention_weights)\n",
    "# print(\"Attention visualization displayed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"background-color:yellow; padding:20px;\">这是测试 HTML</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 测试简单的 HTML 渲染\n",
    "display(HTML('<div style=\"background-color:yellow; padding:20px;\">这是测试 HTML</div>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 测试边界情况\n",
    "# print(\"测试高注意力值:\")\n",
    "# high_attention = [\"高\", \"注意力\", \"值\", \"测试\"]\n",
    "# high_weights = [0.95, 0.99, 0.98, 0.97]\n",
    "# display_attention(high_attention, high_weights)\n",
    "\n",
    "# print(\"测试低注意力值:\")\n",
    "# low_attention = [\"低\", \"注意力\", \"值\", \"测试\"]\n",
    "# low_weights = [0.05, 0.01, 0.02, 0.03]\n",
    "# display_attention(low_attention, low_weights)\n",
    "\n",
    "# # 测试不同offset值\n",
    "# print(\"大字体基础大小:\")\n",
    "# display_attention(sentence, attention_weights, offset=30)\n",
    "\n",
    "# # 测试边界情况\n",
    "# print(\"测试高注意力值:\")\n",
    "# high_attention = [\"高\", \"注意力\", \"值\", \"测试\"]\n",
    "# high_weights = [0.95, 0.99, 0.98, 0.97]\n",
    "# display_attention(high_attention, high_weights)\n",
    "\n",
    "# print(\"测试低注意力值:\")\n",
    "# low_attention = [\"低\", \"注意力\", \"值\", \"测试\"]\n",
    "# low_weights = [0.05, 0.01, 0.02, 0.03]\n",
    "# display_attention(low_attention, low_weights)\n",
    "\n",
    "# # 测试不同offset值\n",
    "# print(\"大字体基础大小:\")\n",
    "# display_attention(sentence, attention_weights, offset=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入CLIP模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import CLIPTokenizer, CLIPTextModel\n",
    "from open_clip import create_model_and_transforms, get_tokenizer\n",
    "import os\n",
    "\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    HfArgumentParser,\n",
    "    PreTrainedTokenizerFast,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    "    AutoModel,\n",
    "    \n",
    "    CLIPPreTrainedModel,\n",
    "    CLIPTextModel, \n",
    "    CLIPTextConfig,\n",
    "    CLIPTokenizerFast, \n",
    "    PreTrainedModel, \n",
    "    CLIPConfig\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "import sys\n",
    "\n",
    "# 将官方 timm 模块的路径添加到 sys.path 的最前面,避免导入libs下的timm\n",
    "sys.path.insert(0, '/opt/conda/envs/uvit/lib/python3.10/site-packages/timm')\n",
    "\n",
    "\n",
    "class AbstractEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def encode(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class FrozenCLIPEmbedder(AbstractEncoder):\n",
    "    \"\"\"Uses the CLIP transformer encoder for text (from Hugging Face)\"\"\"\n",
    "    def __init__(self, version=\"openai/clip-vit-large-patch14\", device=\"cuda\", max_length=77):\n",
    "        super().__init__()\n",
    "        self.tokenizer = CLIPTokenizer.from_pretrained(version)\n",
    "        self.transformer = CLIPTextModel.from_pretrained(version)\n",
    "        self.device = device\n",
    "        self.max_length = max_length\n",
    "        self.freeze()\n",
    "\n",
    "    def freeze(self):\n",
    "        self.transformer = self.transformer.eval()\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, text):\n",
    "        batch_encoding = self.tokenizer(text, truncation=True, max_length=self.max_length, return_length=True,\n",
    "                                        return_overflowing_tokens=False, padding=\"max_length\", return_tensors=\"pt\")\n",
    "        tokens = batch_encoding[\"input_ids\"].to(self.device) # (batch_size, max_length)\n",
    "        outputs = self.transformer(input_ids=tokens) # (batch_size, max_length, hidden_size)\n",
    "\n",
    "        z = outputs.last_hidden_state\n",
    "        return z\n",
    "\n",
    "    def encode(self, text):  \n",
    "        return self(text) # 自动调用forward方法\n",
    "\n",
    "class BioMedClipEmbedder(AbstractEncoder):\n",
    "    \"\"\"Uses the BiomedCLIP transformer encoder for text (from Hugging Face Hub)\"\"\"\n",
    "    def __init__(self, version=\"hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\", device=\"cuda\", max_length=256):\n",
    "        super().__init__()\n",
    "        # Load the model and tokenizer from Hugging Face Hub\n",
    "        self.model, _, preprocess = create_model_and_transforms(version)\n",
    "        self.encoder = self.model.text\n",
    "        self.encoder.output_tokens = True\n",
    "\n",
    "        self.tokenizer = get_tokenizer(version)\n",
    "        self.device = device\n",
    "        self.max_length = max_length\n",
    "        self.freeze()\n",
    "\n",
    "        print(\"\\n\")\n",
    "        print(\"**TextEmbedder**:\", version)\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "    def freeze(self):\n",
    "        \"\"\"Freeze the model parameters to disable training.\"\"\"\n",
    "        self.model = self.model.eval()\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, text):\n",
    "        # Tokenize the input text\n",
    "        token_embeddings = self.tokenizer(text, context_length=self.max_length).to(self.device)\n",
    "        attention_mask = (token_embeddings != 0).long()  # 非零位置为1，零位置为0\n",
    "        outputs = self.encoder(token_embeddings) # (batch_size, max_length, hidden_size)\n",
    "        \n",
    "        # Get the hidden states from the transformer\n",
    "        z = outputs[1] # 取出hidden_size\n",
    "        return token_embeddings, z, attention_mask\n",
    "\n",
    "    def encode(self, text):\n",
    "        return self(text)\n",
    "\n",
    "class PubMedClipEmbedder(AbstractEncoder):\n",
    "    \"\"\"Uses the PubMedCLIP transformer encoder for text embeddings\"\"\"\n",
    "    def __init__(self, version=\"flaviagiammarino/pubmed-clip-vit-base-patch32\", device=\"cuda\", max_length=77):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(version)\n",
    "        self.transformer = CLIPTextModel.from_pretrained(version)\n",
    "        self.device = device\n",
    "        self.max_length = max_length\n",
    "        self.freeze()\n",
    "\n",
    "    def freeze(self):\n",
    "        self.transformer = self.transformer.eval()\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, text):\n",
    "        batch_encoding = self.tokenizer(text, truncation=True, max_length=self.max_length, return_length=True,\n",
    "                                        return_overflowing_tokens=False, padding=\"max_length\", return_tensors=\"pt\")\n",
    "        attention_mask = batch_encoding[\"attention_mask\"].to(self.device)\n",
    "        tokens = batch_encoding[\"input_ids\"].to(self.device)  # (batch_size, max_length)\n",
    "        outputs = self.transformer(input_ids=tokens, attention_mask=attention_mask)  # (batch_size, max_length, hidden_size)\n",
    "        \n",
    "        z = outputs.last_hidden_state\n",
    "        \n",
    "        # 返回原始tokens和特征，以及attention_mask，让调用者知道哪些是padding\n",
    "        return tokens, z, attention_mask\n",
    "\n",
    "    def encode(self, text):  \n",
    "        return self(text) # 自动调用forward方法\n",
    "\n",
    "class BertEmbedder(AbstractEncoder):\n",
    "    \"\"\"Uses the BERT transformer encoder for text (from Hugging Face)\"\"\"\n",
    "    def __init__(self, version=\"michiyasunaga/BioLinkBERT-base\", device=\"cuda\", max_length=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(\"**TextEmbedder**:\", version)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # Load the model and tokenizer from Hugging Face Hub\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(version)\n",
    "        self.bert_model = AutoModel.from_pretrained(version)\n",
    "        self.device = device\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.freeze()\n",
    "\n",
    "    def freeze(self):\n",
    "        self.bert_model = self.bert_model.eval()\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def forward(self, text):\n",
    "        batch_encoding = self.tokenizer(text, truncation=True, max_length=self.max_length, return_length=True,\n",
    "                                        return_overflowing_tokens=False, padding=\"max_length\", return_tensors=\"pt\")\n",
    "        attention_mask = batch_encoding[\"attention_mask\"].to(self.device)\n",
    "        tokens = batch_encoding[\"input_ids\"].to(self.device)  # (batch_size, max_length)\n",
    "        outputs = self.bert_model(input_ids=tokens, attention_mask=attention_mask)  # (batch_size, max_length, hidden_size)\n",
    "        \n",
    "        z = outputs.last_hidden_state\n",
    "        \n",
    "        # 返回原始tokens和特征，以及attention_mask，让调用者知道哪些是padding\n",
    "        return tokens, z, attention_mask\n",
    "\n",
    "    def encode(self, text):  \n",
    "        return self(text) # 自动调用forward方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化文字权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_subword_tokens_bert(tokens, weights):\n",
    "    merged_tokens = []\n",
    "    merged_weights = []\n",
    "    \n",
    "    current_word = []\n",
    "    current_weights = []\n",
    "    \n",
    "    for token, weight in zip(tokens, weights):\n",
    "        if token in [\"[CLS]\", \"[SEP]\"]:  # 特殊符号单独处理\n",
    "            if current_word:\n",
    "                merged_tokens.append(\"\".join(current_word))\n",
    "                merged_weights.append(sum(current_weights)/len(current_weights))\n",
    "                current_word = []\n",
    "                current_weights = []\n",
    "            merged_tokens.append(token)\n",
    "            merged_weights.append(weight)\n",
    "        elif token.startswith(\"##\"):\n",
    "            current_word.append(token[2:])\n",
    "            current_weights.append(weight)\n",
    "        else:\n",
    "            if current_word:\n",
    "                merged_tokens.append(\"\".join(current_word))\n",
    "                merged_weights.append(sum(current_weights)/len(current_weights))\n",
    "            current_word = [token]\n",
    "            current_weights = [weight]\n",
    "    \n",
    "    # 处理剩余词\n",
    "    if current_word:\n",
    "        merged_tokens.append(\"\".join(current_word))\n",
    "        merged_weights.append(sum(current_weights)/len(current_weights))\n",
    "    \n",
    "    return merged_tokens, merged_weights\n",
    "\n",
    "\n",
    "def merge_subword_tokens_clip(tokens, weights):\n",
    "    \"\"\"\n",
    "    处理以 </w> 结尾的词尾标记，合并至标记位置\n",
    "    \n",
    "    示例输入：\n",
    "        tokens = [\"Hello</w>\", \"World</w>\", \"[SEP]\", \"Test\", \"ing</w>\"]\n",
    "        weights = [0.9, 0.8, 1.00.7, 0.6]\n",
    "    \n",
    "    输出：\n",
    "        ([\"Hello\", \"World\", \"[SEP]\", \"Testing\"], [0.9, 0.8, 1.0, 0.65])\n",
    "    \"\"\"\n",
    "    merged_tokens = []\n",
    "    merged_weights = []\n",
    "    \n",
    "    current_word = []\n",
    "    current_weights = []\n",
    "    \n",
    "    for token, weight in zip(tokens, weights):\n",
    "        if token in {\"[CLS]\", \"[SEP]\"}:\n",
    "            if current_word:\n",
    "                merged_tokens.append(\"\".join(current_word))\n",
    "                merged_weights.append(sum(current_weights)/len(current_weights))\n",
    "                current_word = []\n",
    "                current_weights = []\n",
    "            merged_tokens.append(token)\n",
    "            merged_weights.append(weight)\n",
    "            continue\n",
    "            \n",
    "        if token.endswith(\"</w>\"):\n",
    "            current_word.append(token[:-4])\n",
    "            current_weights.append(weight)\n",
    "            merged_tokens.append(\"\".join(current_word))\n",
    "            merged_weights.append(sum(current_weights)/len(current_weights))\n",
    "            current_word = []\n",
    "            current_weights = []\n",
    "        else:\n",
    "            current_word.append(token)\n",
    "            current_weights.append(weight)\n",
    "    \n",
    "    if current_word:\n",
    "        merged_tokens.append(\"\".join(current_word))\n",
    "        merged_weights.append(sum(current_weights)/len(current_weights))\n",
    "        \n",
    "    return merged_tokens, merged_weights\n",
    "\n",
    "\n",
    "\n",
    "def vis_word_label_attention(label, weights, version):\n",
    "    \"\"\"\n",
    "    可视化每个类别的词汇注意力强度\n",
    "    参数：\n",
    "    label - 词汇标签列表（0-3的整数列表）\n",
    "    weights - 对应词汇的注意力权重列表\n",
    "    \"\"\"\n",
    "    # 验证输入合法性\n",
    "    if len(label) != len(weights):\n",
    "        raise ValueError(\"标签和权重列表长度必须一致\")\n",
    "    \n",
    "    # 初始化分类容器\n",
    "    category_weights = {0:[], 1:[], 2:[], 3:[]}\n",
    "    \n",
    "    # 遍历填充数据\n",
    "    for lbl, w in zip(label, weights):\n",
    "        if lbl in category_weights:\n",
    "            category_weights[lbl].append(w)\n",
    "    \n",
    "    # 计算均值（处理空列表避免除零）\n",
    "    category_means = {\n",
    "        k: np.mean(v) if v else 0 \n",
    "        for k, v in category_weights.items()\n",
    "    }\n",
    "    \n",
    "    # 打印结果\n",
    "    print(\"类别 | 平均注意力值\")\n",
    "    print(\"------------------\")\n",
    "    for k in sorted(category_means.keys()):\n",
    "        print(f\"{k:4} | {category_means[k]:.4f}\")\n",
    "    \n",
    "    # 绘图设置\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    categories = ['疾病名词', '程度描述', '位置描述', '其他']\n",
    "    values = [category_means[0], category_means[1], category_means[2], category_means[3]]\n",
    "    \n",
    "    # 创建柱状图\n",
    "    bars = plt.bar(categories, values, color=['#3a5988', '#4a89c0', '#80b8db', '#c5dcee'])\n",
    "    \n",
    "    # 添加数值标签\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{height:.4f}',\n",
    "                 ha='center', va='bottom')\n",
    "    \n",
    "    # 图表装饰\n",
    "    plt.title('各语义类别平均注意力强度', fontsize=14)\n",
    "    plt.xlabel('语义类别', fontsize=12)\n",
    "    plt.ylabel('平均注意力值', fontsize=12)\n",
    "    plt.ylim(0, max(values)*1.2)  # 自动调整y轴范围\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    # plt.show()\n",
    "    # 保存文件\n",
    "    prefix = version.split(\"/\")[-1]\n",
    "    plt.savefig(f'{prefix}_word_vis.jpg', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def visualize_text_attention(text, version, model_type):\n",
    "    if model_type == \"biomedclip\":\n",
    "        clip = BioMedClipEmbedder(version)\n",
    "    elif model_type == \"pubmedclip\":\n",
    "        clip = PubMedClipEmbedder(version)\n",
    "    else:\n",
    "        clip = BertEmbedder(version)\n",
    "    \n",
    "    clip.eval()\n",
    "    clip.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tokens, features, attention_mask = clip.encode(text)\n",
    "    \n",
    "    valid_length = attention_mask[0].sum().item()\n",
    "    valid_tokens = tokens[0, :valid_length]\n",
    "    valid_features = features[0, :valid_length]\n",
    "    \n",
    "    tokens_list = valid_tokens.cpu().numpy().tolist()\n",
    "    if model_type == \"biomedclip\":\n",
    "        decoded_tokens = clip.tokenizer.tokenizer.convert_ids_to_tokens(tokens_list)\n",
    "    else:\n",
    "        decoded_tokens = clip.tokenizer.convert_ids_to_tokens(tokens_list)\n",
    "    \n",
    "    # 提取[CLS] token的特征向量\n",
    "    cls_token = valid_features[0]  # 维度 [hidden_dim]\n",
    "    \n",
    "    # 计算余弦相似度（带非线性增强）\n",
    "    similarity_scores = torch.nn.functional.cosine_similarity(\n",
    "        valid_features,\n",
    "        cls_token.unsqueeze(0).expand_as(valid_features),\n",
    "        dim=1\n",
    "    )\n",
    "    enhanced_p = {\"bert_series\":(5,[0.01, 0.95]), \"biomedclip\":(5,[0.02, 0.9]), \"pubmedclip\":(5,[0.02, 0.9])}\n",
    "    \n",
    "    print(\"enhanced_p:\", enhanced_p[model_type][0], enhanced_p[model_type][1])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # 非线性增强（指数放大差异）\n",
    "    enhanced_scores = torch.exp(enhanced_p[model_type][0] * similarity_scores)  # 可调节的放大系数\n",
    "    \n",
    "    # 分位数归一化（增强中间值的区分度）\n",
    "    quantiles = torch.quantile(enhanced_scores, torch.tensor(enhanced_p[model_type][1]).to(device))  # 去除极端值\n",
    "    # print(quantiles[0], quantiles[1])\n",
    "    clipped_scores = torch.clamp(enhanced_scores, quantiles[0], quantiles[1])\n",
    "    token_importance = (clipped_scores - clipped_scores.min()) / (clipped_scores.max() - clipped_scores.min())\n",
    "    \n",
    "    token_importance = token_importance.cpu().numpy().tolist()\n",
    "    \n",
    "    # 合并子词并计算平均权重\n",
    "    if model_type == \"pubmedclip\":\n",
    "        merged_tokens, merged_weights = merge_subword_tokens_clip(decoded_tokens, token_importance)\n",
    "    else:\n",
    "        merged_tokens, merged_weights = merge_subword_tokens_bert(decoded_tokens, token_importance)\n",
    "    \n",
    "    print(\"Report:\",merged_tokens)\n",
    "    print(\"length of report:\", len(merged_tokens))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    label =[3, 3, 3, 3, 3, 3, 2, 1, 2, 0, 3, 1, 2, 0, 3, 1, 0, 3, 3, 2, 3, 3, 3, 2, 2, 2, 3, 3, 3, 1, 2, 0, 3, 2, 0, 3, 3, 3, 1, 0, 0, 3, 1, 2, 0, 3]\n",
    "    print(len(label))  # 不包括[CLS]和[SEP]\n",
    "    if model_type == \"pubmedclip\":\n",
    "        vis_word_label_attention(label, merged_weights[0:-1], version)\n",
    "    else:\n",
    "        vis_word_label_attention(label, merged_weights[1:-1], version)\n",
    "    \n",
    "    \n",
    "    # merged_tokens = [merged_token.replace(\"</w>\", \"\") for merged_token in merged_tokens]\n",
    "    display_attention(merged_tokens[1:-1], merged_weights[1:-1])  # 不可视化[CLS]和[SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chest X-ray reveals bilateral diffuse interstitial edema with patchy alveolar infiltrates and multifocal consolidations in the mid-to-lower lung zones, accompanied by subtle air bronchograms and vascular congestion, suggestive of progressive hydrostatic edema and evolving lobar consolidation.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.CUDA_VISIBLE_DEVICES = '0'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 使用示例\n",
    "# search_query = np.load(\"/cpfs01/projects-HDD/cfff-906dc71fafda_HDD/gbw_21307130160/U-ViT/tools/Visualization/language/0.npy\", allow_pickle=True).item()[\"prompt\"]\n",
    "search_query = \"The chest X-ray reveals bilateral diffuse interstitial edema with patchy alveolar infiltrates and multifocal consolidations in the mid-to-lower lung zones, accompanied by subtle air bronchograms and vascular congestion, suggestive of progressive hydrostatic edema and evolving lobar consolidation.\"\n",
    "print(search_query)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert-series model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**TextEmbedder**: cambridgeltl/SapBERT-from-PubMedBERT-fulltext\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/bionlp/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enhanced_p: 5 [0.01, 0.95]\n",
      "\n",
      "\n",
      "Report: ['[CLS]', 'the', 'chest', 'x', '-', 'ray', 'reveals', 'bilateral', 'diffuse', 'interstitial', 'edema', 'with', 'patchy', 'alveolar', 'infiltrates', 'and', 'multifocal', 'consolidations', 'in', 'the', 'mid', '-', 'to', '-', 'lower', 'lung', 'zones', ',', 'accompanied', 'by', 'subtle', 'air', 'bronchograms', 'and', 'vascular', 'congestion', ',', 'suggestive', 'of', 'progressive', 'hydrostatic', 'edema', 'and', 'evolving', 'lobar', 'consolidation', '.', '[SEP]']\n",
      "length of report: 48\n",
      "\n",
      "\n",
      "46\n",
      "类别 | 平均注意力值\n",
      "------------------\n",
      "   0 | 0.3045\n",
      "   1 | 0.4063\n",
      "   2 | 0.2675\n",
      "   3 | 0.6339\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <script src=\"https://d3js.org/d3.v4.min.js\"></script>\n",
       "    <style>\n",
       "    .tooltip {\n",
       "        position: relative;\n",
       "        display: inline-block;\n",
       "        border-bottom: 1px dotted black;\n",
       "    }\n",
       "    .tooltip:hover .tooltiptext {\n",
       "        visibility: visible;\n",
       "    }\n",
       "    .tooltip .tooltiptext {\n",
       "        visibility: hidden;\n",
       "        font-size:15px;\n",
       "        width: 60px;\n",
       "        background-color: black;\n",
       "        color: #fff;\n",
       "        text-align: center;\n",
       "        border-radius: 6px;\n",
       "        padding: 1px 0;\n",
       "        position: absolute;\n",
       "        left: 50%;\n",
       "        margin-left: -60px;\n",
       "    }\n",
       "    </style>\n",
       "    <script>\n",
       "    function tohex(fraction) {\n",
       "        var value = Math.round(255 * fraction);\n",
       "        var hex = value.toString(16).toUpperCase();\n",
       "        if (hex.length === 1) {\n",
       "            hex = '0' + hex;\n",
       "        }\n",
       "        return hex;\n",
       "    }\n",
       "\n",
       "    d3.select('#text')\n",
       "      .selectAll('tspan')\n",
       "      .data([{\"token\": \"the\", \"weight\": 0.7957518100738525}, {\"token\": \"chest\", \"weight\": 0.23010441660881042}, {\"token\": \"x\", \"weight\": 0.2967868745326996}, {\"token\": \"-\", \"weight\": 0.4430370628833771}, {\"token\": \"ray\", \"weight\": 0.13582547008991241}, {\"token\": \"reveals\", \"weight\": 0.8222862482070923}, {\"token\": \"bilateral\", \"weight\": 0.37058335542678833}, {\"token\": \"diffuse\", \"weight\": 0.3081664443016052}, {\"token\": \"interstitial\", \"weight\": 0.17388221621513367}, {\"token\": \"edema\", \"weight\": 0.31963756680488586}, {\"token\": \"with\", \"weight\": 0.725036084651947}, {\"token\": \"patchy\", \"weight\": 0.32891348004341125}, {\"token\": \"alveolar\", \"weight\": 0.0}, {\"token\": \"infiltrates\", \"weight\": 0.26843228936195374}, {\"token\": \"and\", \"weight\": 0.6951205730438232}, {\"token\": \"multifocal\", \"weight\": 0.16537806391716003}, {\"token\": \"consolidations\", \"weight\": 0.20669609354808927}, {\"token\": \"in\", \"weight\": 0.6377861499786377}, {\"token\": \"the\", \"weight\": 0.6772854924201965}, {\"token\": \"mid\", \"weight\": 0.13346229493618011}, {\"token\": \"-\", \"weight\": 0.3487258553504944}, {\"token\": \"to\", \"weight\": 0.3868708610534668}, {\"token\": \"-\", \"weight\": 0.46091097593307495}, {\"token\": \"lower\", \"weight\": 0.19940857589244843}, {\"token\": \"lung\", \"weight\": 0.22212937474250793}, {\"token\": \"zones\", \"weight\": 0.5545825958251953}, {\"token\": \",\", \"weight\": 0.9479465484619141}, {\"token\": \"accompanied\", \"weight\": 0.7386683225631714}, {\"token\": \"by\", \"weight\": 0.7157278656959534}, {\"token\": \"subtle\", \"weight\": 0.6376320123672485}, {\"token\": \"air\", \"weight\": 0.1838388442993164}, {\"token\": \"bronchograms\", \"weight\": 0.2650550976395607}, {\"token\": \"and\", \"weight\": 0.8170161247253418}, {\"token\": \"vascular\", \"weight\": 0.434573769569397}, {\"token\": \"congestion\", \"weight\": 0.3460090756416321}, {\"token\": \",\", \"weight\": 0.8373941779136658}, {\"token\": \"suggestive\", \"weight\": 0.7195008993148804}, {\"token\": \"of\", \"weight\": 0.8137351870536804}, {\"token\": \"progressive\", \"weight\": 0.5259722471237183}, {\"token\": \"hydrostatic\", \"weight\": 0.4151940643787384}, {\"token\": \"edema\", \"weight\": 0.36290669441223145}, {\"token\": \"and\", \"weight\": 0.7013606429100037}, {\"token\": \"evolving\", \"weight\": 0.4717167615890503}, {\"token\": \"lobar\", \"weight\": 0.40299923717975616}, {\"token\": \"consolidation\", \"weight\": 0.25174224376678467}, {\"token\": \".\", \"weight\": 1.0}])\n",
       "      .enter()\n",
       "      .append('tspan')\n",
       "      .style('font-family', 'verdana')\n",
       "      \n",
       "      .style('margin', '2px')\n",
       "      .attr('class', 'tooltip')\n",
       "      .style('font-size', function(d) { return 18 + 0 * d.weight + \"px\"; })\n",
       "      .style('background-color', function(d) { \n",
       "          var intensity = tohex(1 - d.weight);\n",
       "          return '#FF' + intensity + intensity; \n",
       "      })\n",
       "      .text(function(d) { return d.token + ' '; })\n",
       "      .append('span')\n",
       "      .attr('class', 'tooltiptext')\n",
       "      .text(function(d) { return Math.round(d.weight * 10000) / 100; });\n",
       "    </script>\n",
       "    <div id='text' style=\"margin-left:50px;\"></div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# michiyasunaga/BioLinkBERT-base \n",
    "# michiyasunaga/BioLinkBERT-large (hidden_size 1024, 似乎不太可行)\n",
    "# microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\n",
    "# cambridgeltl/SapBERT-from-PubMedBERT-fulltext\n",
    "# StanfordAIMI/RadBERT\n",
    "\n",
    "visualize_text_attention(search_query, version=\"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\", model_type=\"bert_series\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pubmedclip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/bionlp/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enhanced_p: 5 [0.02, 0.9]\n",
      "\n",
      "\n",
      "Report: ['<|startoftext|>the', 'chest', 'x', '-', 'ray', 'reveals', 'bilateral', 'diffuse', 'interstitial', 'edema', 'with', 'patchy', 'alveolar', 'infiltrates', 'and', 'multifocal', 'consolidations', 'in', 'the', 'mid', '-', 'to', '-', 'lower', 'lung', 'zones', ',', 'accompanied', 'by', 'subtle', 'air', 'bronchograms', 'and', 'vascular', 'congestion', ',', 'suggestive', 'of', 'progressive', 'hydrostatic', 'edema', 'and', 'evolving', 'lobar', 'consolidation', '.', '<|endoftext|>']\n",
      "length of report: 47\n",
      "\n",
      "\n",
      "46\n",
      "类别 | 平均注意力值\n",
      "------------------\n",
      "   0 | 0.2420\n",
      "   1 | 0.2588\n",
      "   2 | 0.3368\n",
      "   3 | 0.4186\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <script src=\"https://d3js.org/d3.v4.min.js\"></script>\n",
       "    <style>\n",
       "    .tooltip {\n",
       "        position: relative;\n",
       "        display: inline-block;\n",
       "        border-bottom: 1px dotted black;\n",
       "    }\n",
       "    .tooltip:hover .tooltiptext {\n",
       "        visibility: visible;\n",
       "    }\n",
       "    .tooltip .tooltiptext {\n",
       "        visibility: hidden;\n",
       "        font-size:15px;\n",
       "        width: 60px;\n",
       "        background-color: black;\n",
       "        color: #fff;\n",
       "        text-align: center;\n",
       "        border-radius: 6px;\n",
       "        padding: 1px 0;\n",
       "        position: absolute;\n",
       "        left: 50%;\n",
       "        margin-left: -60px;\n",
       "    }\n",
       "    </style>\n",
       "    <script>\n",
       "    function tohex(fraction) {\n",
       "        var value = Math.round(255 * fraction);\n",
       "        var hex = value.toString(16).toUpperCase();\n",
       "        if (hex.length === 1) {\n",
       "            hex = '0' + hex;\n",
       "        }\n",
       "        return hex;\n",
       "    }\n",
       "\n",
       "    d3.select('#text')\n",
       "      .selectAll('tspan')\n",
       "      .data([{\"token\": \"chest\", \"weight\": 1.0}, {\"token\": \"x\", \"weight\": 1.0}, {\"token\": \"-\", \"weight\": 0.5417144894599915}, {\"token\": \"ray\", \"weight\": 0.9108093976974487}, {\"token\": \"reveals\", \"weight\": 1.0}, {\"token\": \"bilateral\", \"weight\": 0.18987345695495605}, {\"token\": \"diffuse\", \"weight\": 0.1939079537987709}, {\"token\": \"interstitial\", \"weight\": 0.20090772164985538}, {\"token\": \"edema\", \"weight\": 0.3958141505718231}, {\"token\": \"with\", \"weight\": 1.0}, {\"token\": \"patchy\", \"weight\": 0.09915124624967575}, {\"token\": \"alveolar\", \"weight\": 0.19936753250658512}, {\"token\": \"infiltrates\", \"weight\": 0.28798413276672363}, {\"token\": \"and\", \"weight\": 0.3583618402481079}, {\"token\": \"multifocal\", \"weight\": 0.41883164644241333}, {\"token\": \"consolidations\", \"weight\": 0.24046571661407748}, {\"token\": \"in\", \"weight\": 0.2680344879627228}, {\"token\": \"the\", \"weight\": 0.5853316783905029}, {\"token\": \"mid\", \"weight\": 0.18819503486156464}, {\"token\": \"-\", \"weight\": 0.0}, {\"token\": \"to\", \"weight\": 0.02075532265007496}, {\"token\": \"-\", \"weight\": 0.0}, {\"token\": \"lower\", \"weight\": 0.5415275692939758}, {\"token\": \"lung\", \"weight\": 0.6717607378959656}, {\"token\": \"zones\", \"weight\": 0.5422541499137878}, {\"token\": \",\", \"weight\": 0.13636812567710876}, {\"token\": \"accompanied\", \"weight\": 0.14053373038768768}, {\"token\": \"by\", \"weight\": 0.18977370858192444}, {\"token\": \"subtle\", \"weight\": 0.010608382523059845}, {\"token\": \"air\", \"weight\": 0.17872971296310425}, {\"token\": \"bronchograms\", \"weight\": 0.2923280621568362}, {\"token\": \"and\", \"weight\": 0.3631950318813324}, {\"token\": \"vascular\", \"weight\": 0.11563028395175934}, {\"token\": \"congestion\", \"weight\": 0.05847406014800072}, {\"token\": \",\", \"weight\": 0.08812524378299713}, {\"token\": \"suggestive\", \"weight\": 0.19062803126871586}, {\"token\": \"of\", \"weight\": 0.03772452473640442}, {\"token\": \"progressive\", \"weight\": 0.6120666861534119}, {\"token\": \"hydrostatic\", \"weight\": 0.18689515441656113}, {\"token\": \"edema\", \"weight\": 0.11244048830121756}, {\"token\": \"and\", \"weight\": 0.07012183964252472}, {\"token\": \"evolving\", \"weight\": 0.21817322075366974}, {\"token\": \"lobar\", \"weight\": 0.5400249809026718}, {\"token\": \"consolidation\", \"weight\": 0.36196818947792053}, {\"token\": \".\", \"weight\": 0.3068743646144867}])\n",
       "      .enter()\n",
       "      .append('tspan')\n",
       "      .style('font-family', 'verdana')\n",
       "      \n",
       "      .style('margin', '2px')\n",
       "      .attr('class', 'tooltip')\n",
       "      .style('font-size', function(d) { return 18 + 0 * d.weight + \"px\"; })\n",
       "      .style('background-color', function(d) { \n",
       "          var intensity = tohex(1 - d.weight);\n",
       "          return '#FF' + intensity + intensity; \n",
       "      })\n",
       "      .text(function(d) { return d.token + ' '; })\n",
       "      .append('span')\n",
       "      .attr('class', 'tooltiptext')\n",
       "      .text(function(d) { return Math.round(d.weight * 10000) / 100; });\n",
       "    </script>\n",
       "    <div id='text' style=\"margin-left:50px;\"></div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_text_attention(search_query, version=\"openai/clip-vit-base-patch32\", model_type=\"pubmedclip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## biomedclip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/bionlp/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**TextEmbedder**: hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\n",
      "\n",
      "\n",
      "enhanced_p: 5 [0.02, 0.9]\n",
      "\n",
      "\n",
      "Report: ['[CLS]', 'the', 'chest', 'x', '-', 'ray', 'reveals', 'bilateral', 'diffuse', 'interstitial', 'edema', 'with', 'patchy', 'alveolar', 'infiltrates', 'and', 'multifocal', 'consolidations', 'in', 'the', 'mid', '-', 'to', '-', 'lower', 'lung', 'zones', ',', 'accompanied', 'by', 'subtle', 'air', 'bronchograms', 'and', 'vascular', 'congestion', ',', 'suggestive', 'of', 'progressive', 'hydrostatic', 'edema', 'and', 'evolving', 'lobar', 'consolidation', '.', '[SEP]']\n",
      "length of report: 48\n",
      "\n",
      "\n",
      "46\n",
      "类别 | 平均注意力值\n",
      "------------------\n",
      "   0 | 0.0790\n",
      "   1 | 0.0954\n",
      "   2 | 0.1274\n",
      "   3 | 0.6564\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <script src=\"https://d3js.org/d3.v4.min.js\"></script>\n",
       "    <style>\n",
       "    .tooltip {\n",
       "        position: relative;\n",
       "        display: inline-block;\n",
       "        border-bottom: 1px dotted black;\n",
       "    }\n",
       "    .tooltip:hover .tooltiptext {\n",
       "        visibility: visible;\n",
       "    }\n",
       "    .tooltip .tooltiptext {\n",
       "        visibility: hidden;\n",
       "        font-size:15px;\n",
       "        width: 60px;\n",
       "        background-color: black;\n",
       "        color: #fff;\n",
       "        text-align: center;\n",
       "        border-radius: 6px;\n",
       "        padding: 1px 0;\n",
       "        position: absolute;\n",
       "        left: 50%;\n",
       "        margin-left: -60px;\n",
       "    }\n",
       "    </style>\n",
       "    <script>\n",
       "    function tohex(fraction) {\n",
       "        var value = Math.round(255 * fraction);\n",
       "        var hex = value.toString(16).toUpperCase();\n",
       "        if (hex.length === 1) {\n",
       "            hex = '0' + hex;\n",
       "        }\n",
       "        return hex;\n",
       "    }\n",
       "\n",
       "    d3.select('#text')\n",
       "      .selectAll('tspan')\n",
       "      .data([{\"token\": \"the\", \"weight\": 1.0}, {\"token\": \"chest\", \"weight\": 0.3387987017631531}, {\"token\": \"x\", \"weight\": 0.3918054699897766}, {\"token\": \"-\", \"weight\": 1.0}, {\"token\": \"ray\", \"weight\": 0.43805134296417236}, {\"token\": \"reveals\", \"weight\": 1.0}, {\"token\": \"bilateral\", \"weight\": 0.18499301373958588}, {\"token\": \"diffuse\", \"weight\": 0.052814241498708725}, {\"token\": \"interstitial\", \"weight\": 0.1232907697558403}, {\"token\": \"edema\", \"weight\": 0.0285341814160347}, {\"token\": \"with\", \"weight\": 0.6646978855133057}, {\"token\": \"patchy\", \"weight\": 0.04296695813536644}, {\"token\": \"alveolar\", \"weight\": 0.06742771714925766}, {\"token\": \"infiltrates\", \"weight\": 0.046423546969890594}, {\"token\": \"and\", \"weight\": 0.6280466914176941}, {\"token\": \"multifocal\", \"weight\": 0.051978182047605515}, {\"token\": \"consolidations\", \"weight\": 0.27773954649455845}, {\"token\": \"in\", \"weight\": 0.8895667791366577}, {\"token\": \"the\", \"weight\": 0.9704325795173645}, {\"token\": \"mid\", \"weight\": 0.2715041935443878}, {\"token\": \"-\", \"weight\": 0.6438373327255249}, {\"token\": \"to\", \"weight\": 0.3882145583629608}, {\"token\": \"-\", \"weight\": 0.6047255992889404}, {\"token\": \"lower\", \"weight\": 0.06862283498048782}, {\"token\": \"lung\", \"weight\": 0.17364022135734558}, {\"token\": \"zones\", \"weight\": 0.20628805458545685}, {\"token\": \",\", \"weight\": 0.6488659381866455}, {\"token\": \"accompanied\", \"weight\": 0.41799396276474}, {\"token\": \"by\", \"weight\": 0.5492618680000305}, {\"token\": \"subtle\", \"weight\": 0.09629183262586594}, {\"token\": \"air\", \"weight\": 0.062305860221385956}, {\"token\": \"bronchograms\", \"weight\": 0.1032177656161366}, {\"token\": \"and\", \"weight\": 0.5721465945243835}, {\"token\": \"vascular\", \"weight\": 0.11632154136896133}, {\"token\": \"congestion\", \"weight\": 0.10278583317995071}, {\"token\": \",\", \"weight\": 0.6331835985183716}, {\"token\": \"suggestive\", \"weight\": 0.3876710534095764}, {\"token\": \"of\", \"weight\": 0.7311648726463318}, {\"token\": \"progressive\", \"weight\": 0.2143043428659439}, {\"token\": \"hydrostatic\", \"weight\": 0.036256156861782074}, {\"token\": \"edema\", \"weight\": 0.025732476264238358}, {\"token\": \"and\", \"weight\": 0.541710376739502}, {\"token\": \"evolving\", \"weight\": 0.1142812967300415}, {\"token\": \"lobar\", \"weight\": 0.0}, {\"token\": \"consolidation\", \"weight\": 0.011044355109333992}, {\"token\": \".\", \"weight\": 1.0}])\n",
       "      .enter()\n",
       "      .append('tspan')\n",
       "      .style('font-family', 'verdana')\n",
       "      \n",
       "      .style('margin', '2px')\n",
       "      .attr('class', 'tooltip')\n",
       "      .style('font-size', function(d) { return 18 + 0 * d.weight + \"px\"; })\n",
       "      .style('background-color', function(d) { \n",
       "          var intensity = tohex(1 - d.weight);\n",
       "          return '#FF' + intensity + intensity; \n",
       "      })\n",
       "      .text(function(d) { return d.token + ' '; })\n",
       "      .append('span')\n",
       "      .attr('class', 'tooltiptext')\n",
       "      .text(function(d) { return Math.round(d.weight * 10000) / 100; });\n",
       "    </script>\n",
       "    <div id='text' style=\"margin-left:50px;\"></div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_text_attention(search_query, version=\"hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\", model_type=\"biomedclip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "收集所有编码器的文本表现，再画一个雷达图，结束文本可视化"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bionlp",
   "language": "python",
   "name": "bionlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
